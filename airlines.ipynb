{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as ps\n",
    "tweets = ps.read_csv(\"data/tweets_airlines_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5,70306133677761E+017</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5,70301130888122E+017</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5,70301083672814E+017</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5,70301031407624E+017</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5,70300817074463E+017</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  5,70306133677761E+017  neutral           1.0000                         \n",
       "1  5,70301130888122E+017  positive          0.3486                         \n",
       "2  5,70301083672814E+017  neutral           0.6837                         \n",
       "3  5,70301031407624E+017  negative          1.0000                         \n",
       "4  5,70300817074463E+017  negative          1.0000                         \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0  NaN           NaN                         Virgin America   \n",
       "1  NaN            0.0000                     Virgin America   \n",
       "2  NaN           NaN                         Virgin America   \n",
       "3  Bad Flight     0.7033                     Virgin America   \n",
       "4  Can't Tell     1.0000                     Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0  NaN                    cairdin     NaN                 0               \n",
       "1  NaN                    jnardino    NaN                 0               \n",
       "2  NaN                    yvonnalynn  NaN                 0               \n",
       "3  NaN                    jnardino    NaN                 0               \n",
       "4  NaN                    jnardino    NaN                 0               \n",
       "\n",
       "                                                                                                                             text  \\\n",
       "0  @VirginAmerica What @dhepburn said.                                                                                              \n",
       "1  @VirginAmerica plus you've added commercials to the experience... tacky.                                                         \n",
       "2  @VirginAmerica I didn't today... Must mean I need to take another trip!                                                          \n",
       "3  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse   \n",
       "4  @VirginAmerica and it's a really big bad thing about it                                                                          \n",
       "\n",
       "  tweet_coord              tweet_created tweet_location  \\\n",
       "0  NaN         2015-02-24 11:35:52 -0800  NaN             \n",
       "1  NaN         2015-02-24 11:15:59 -0800  NaN             \n",
       "2  NaN         2015-02-24 11:15:48 -0800  Lets Play       \n",
       "3  NaN         2015-02-24 11:15:36 -0800  NaN             \n",
       "4  NaN         2015-02-24 11:14:45 -0800  NaN             \n",
       "\n",
       "                user_timezone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Pacific Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  \n",
       "3  Pacific Time (US & Canada)  \n",
       "4  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_texts = tweets[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknz = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_text = tweets_texts[\"text\"][0:30]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tknz.tokenize(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\n",
      "\"\n",
      "#\n",
      "$\n",
      "%\n",
      "&\n",
      "'\n",
      "(\n",
      ")\n",
      "*\n",
      "+\n",
      ",\n",
      "-\n",
      ".\n",
      "/\n",
      ":\n",
      ";\n",
      "<\n",
      "=\n",
      ">\n",
      "?\n",
      "@\n",
      "[\n",
      "\\\n",
      "]\n",
      "^\n",
      "_\n",
      "`\n",
      "{\n",
      "|\n",
      "}\n",
      "~\n"
     ]
    }
   ],
   "source": [
    "for char in string.punctuation:\n",
    "    print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct = string.punctuation\n",
    "punct += \"‚Äù\"\n",
    "punct += \"'\"\n",
    "punct += \"‚Äô\"\n",
    "punct += \"‚Ä¶\"\n",
    "\n",
    "import string\n",
    "import re\n",
    "translate_table = dict((ord(char), None) for char in punct)   \n",
    "\n",
    "def remove_hashtag(text):\n",
    "    return text[1:] if text.startswith(\"#\") else text\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    tokens = tknz.tokenize(text)\n",
    "    filtered_tokens = [remove_hashtag(token) for token in tokens if token not in punct]\n",
    "    filtered_tokens = [token for token in filtered_tokens if \"...\" not in token]\n",
    "    tokenized = \" \".join(filtered_tokens)\n",
    "    #return tokenized\n",
    "    #translated_tokens = tokenized.translate(translate_table)\n",
    "    return ' '.join(tokenized.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fred/anaconda2/envs/airlines/lib/python3.5/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tweets_texts['text_clean'] = tweets_texts.apply(lambda row: clean_text(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     what said                                                                                                                         \n",
      "1     plus you've added commercials to the experience tacky                                                                             \n",
      "2     i didn't today must mean i need to take another trip                                                                              \n",
      "3     it's really aggressive to blast obnoxious entertainment in your guests faces they have little recourse                            \n",
      "4     and it's a really big bad thing about it                                                                                          \n",
      "5     seriously would pay 30 a flight for seats that didn't have this playing it's really the only bad thing about flying va            \n",
      "6     yes nearly every time i fly vx this ‚Äú ear worm won ‚Äô t go away :)                                                                 \n",
      "7     really missed a prime opportunity for men without hats parody there                                                               \n",
      "8     well i didn't but now i do :-D                                                                                                    \n",
      "9     it was amazing and arrived an hour early you're too good to me                                                                    \n",
      "10    did you know that suicide is the second leading cause of death among teens 10-24                                                  \n",
      "11    i <3 pretty graphics so much better than minimal iconography :D                                                                   \n",
      "12    this is such a great deal already thinking about my 2nd trip to i haven't even gone on my 1st trip yet ;p                         \n",
      "13    i'm flying your fabulous seductive skies again u take all the stress away from travel                                             \n",
      "14    thanks                                                                                                                            \n",
      "15    sfo-pdx schedule is still mia                                                                                                     \n",
      "16    so excited for my first cross country flight lax to mco i've heard nothing but great things about virgin america 29daystogo       \n",
      "17    i flew from nyc to sfo last week and couldn't fully sit in my seat due to two large gentleman on either side of me help           \n",
      "18    i ‚ù§ Ô∏è flying ‚ò∫ Ô∏è üëç                                                                                                                \n",
      "19    you know what would be amazingly awesome bos-fll please i want to fly with only you                                               \n",
      "20    why are your first fares in may over three times more than other carriers when all seats are available to select                  \n",
      "21    i love this graphic                                                                                                               \n",
      "22    i love the hipster innovation you are a feel good brand                                                                           \n",
      "23    will you be making bos las non stop permanently anytime soon                                                                      \n",
      "24    you guys messed up my seating .. i reserved seating with my friends and you guys gave my seat away üò° i want free internet         \n",
      "25    status match program i applied and it's been three weeks called and emailed with no response                                      \n",
      "26    what happened 2 ur vegan food options at least say on ur site so i know i won't be able 2 eat anything for next 6 hrs fail        \n",
      "27    do you miss me don't worry we'll be together very soon                                                                            \n",
      "28    amazing to me that we can't get any cold air from the vents vx358 noair worstflightever roasted sfotobos                          \n",
      "29    lax to ewr middle seat on a red eye such a noob maneuver sendambien andchexmix                                                    \n",
      "                                           ...                                                                                          \n",
      "70    need to change reservation have virgin credit card do i need to modify on phone to waive change fee or can i do online            \n",
      "71    i emailed your customer service team let me know if you need the tracking number                                                  \n",
      "72    hi i just booked a flight but need to add baggage how can i do this                                                               \n",
      "73    your airline is awesome but your lax loft needs to step up its game 40 for dirty tables and floors                                \n",
      "74    not worried it's been a great ride in a new plane with great crew all airlines should be like this                                \n",
      "75    awesome i flew yall sat morning any way we can correct my bill                                                                    \n",
      "76    or watch some of the best student films in the country at 35,000 feet cmfat35000feet                                              \n",
      "77    first time flying you all do you have a different rate policy for media bags thanks                                               \n",
      "78    what is going on with customer service is there anyway to speak to a human asap thank you                                         \n",
      "79    what happened to doom                                                                                                             \n",
      "80    why can't you supp the biz traveler like and have customer service like neverflyvirginforbusiness                                 \n",
      "81    i've applied more then once to be a member of the inflight crew team im 100 interested flightattendant dreampath g                \n",
      "82    you're the best whenever i begrudgingly use any other airline i'm delayed and late flight :(                                      \n",
      "83    i have no interesting flying with you after this i will cancelled flight my next four flights i planned neverflyvirginforbusiness \n",
      "84    it was a disappointing experience which will be shared with every business traveler i meet neverflyvirgin                         \n",
      "85    i ‚Äô m having trouble adding this flight my wife booked to my elevate account help                                                 \n",
      "86    can't bring up my reservation online using flight booking problems code                                                           \n",
      "87    random q what's the distribution of elevate avatars i bet that kitty has a disproportionate share                                 \n",
      "88    i <3 flying va but life happens and i am trying to change my trip jperhi can you help.va home page will not let me                \n",
      "89    why is the site down when will it be back up                                                                                      \n",
      "90    you down with rnp yeah you know me                                                                                                \n",
      "91    hi i did not get points on my elevate account for my most recent flight how do i add the flight and points to my account          \n",
      "92    i like the tv and interesting video just disappointed in cancelled flightled flight when other flights went out to jfk on saturday\n",
      "93    just landed in lax an hour after i should of been here your no late flight bag check is not business travel friendly nomorevirgin \n",
      "94    why is flight 345 redirected                                                                                                      \n",
      "95    is it me or is your website down btw your new website isn't a great user experience time for another redesign                     \n",
      "96    i can't check in or add a bag your website isn't working i've tried both desktop and mobile                                       \n",
      "97    let 2 scanned in passengers leave the plane than told someone to remove their bag from 1st class bin uncomfortable                \n",
      "98    what is your phone number i can't find who to call about a flight reservation                                                     \n",
      "99    is anyone doing anything there today website is useless and no one is answering the phone                                         \n",
      "Name: text_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sample_clean_text = tweets_texts[\"text_clean\"][0:100]\n",
    "print(sample_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_texts.to_csv(path_or_buf=\"data/tweets_airlines_clean.csv\", header=True, index=False, sep=',', columns=[\"text_clean\", \"airline_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets.to_csv(path_or_buf=\"data/tweets_airlines_clean.csv\", header=True, index=False, sep=',', columns=[\"text\", \"airline_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_exclamation_point(tweet):\n",
    "    return True if \"!\" in tweet else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"exclamation\"] = tweets_texts.apply(lambda row: has_exclamation_point(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_interrogation_point(tweet):\n",
    "    return True if \"?\" in tweet else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"interrogation\"] = tweets_texts.apply(lambda row: has_interrogation_point(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_ellipsis(tweet):\n",
    "    three_points = True if \"...\" in tweet else False\n",
    "    single_char = True if \"‚Ä¶\" in tweet else False\n",
    "    return three_points or single_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"ellipsis\"] = tweets_texts.apply(lambda row: has_ellipsis(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"length\"] = tweets_texts.apply(lambda row: len(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_texts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ttp import ttp\n",
    "p = ttp.Parser()\n",
    "\n",
    "def has_link(tweet):\n",
    "    parsed_tweet = p.parse(tweet)    \n",
    "    return True if len(parsed_tweet.urls) > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"links\"] = tweets_texts.apply(lambda row: has_link(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_texts.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_emojis(tweet):\n",
    "    emoticons = re.findall(r'[\\U0001f600-\\U0001f650]', tweet)\n",
    "    count = sum(1 for _ in emoticons)\n",
    "    return True if count > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"emojis\"] = tweets_texts.apply(lambda row: has_emojis(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def has_hashtag(tweet):\n",
    "    parsed_tweet = p.parse(tweet)    \n",
    "    return True if len(parsed_tweet.tags) > 0 else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_texts[\"hashtags\"] = tweets_texts.apply(lambda row: has_hashtag(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_texts.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words(\"english\"))     \n",
    "\n",
    "def remove_stop_words(tweet):\n",
    "    words = [word for word in tweet.split(\" \") if word not in stopwords]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_texts[\"text_clean_stop\"] = tweets_texts.apply(lambda row: remove_stop_words(row[\"text_clean\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_texts.to_csv(path_or_buf=\"data/tweets_airlines_clean_extended.csv\", header=True, index=False, sep=',', columns=[\"text_clean\", \"exclamation\", \"emojis\", \"links\", \"hashtags\", \"airline_sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train,test = train_test_split(tweets_texts,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_clean_tweet=[]\n",
    "for tweet in train['text_clean']:\n",
    "    train_clean_tweet.append(tweet)\n",
    "test_clean_tweet=[]\n",
    "for tweet in test['text_clean']:\n",
    "    test_clean_tweet.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(analyzer = \"word\")\n",
    "train_features= v.fit_transform(train_clean_tweet)\n",
    "test_features=v.transform(test_clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Classifiers = [\n",
    "    LogisticRegression(C=0.000000001,solver='liblinear',max_iter=200),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(n_estimators=200),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dense_features=train_features.toarray()\n",
    "dense_test= test_features.toarray()\n",
    "Accuracy=[]\n",
    "Model=[]\n",
    "for classifier in Classifiers:\n",
    "    try:\n",
    "        fit = classifier.fit(train_features,train['airline_sentiment'])\n",
    "        pred = fit.predict(test_features)\n",
    "    except Exception:\n",
    "        fit = classifier.fit(dense_features,train['airline_sentiment'])\n",
    "        pred = fit.predict(dense_test)\n",
    "    accuracy = accuracy_score(pred,test['airline_sentiment'])\n",
    "    Accuracy.append(accuracy)\n",
    "    Model.append(classifier.__class__.__name__)\n",
    "    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_to_words(raw_tweet):\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \",raw_tweet) \n",
    "    words = letters_only.lower().split()                             \n",
    "    meaningful_words = [w for w in words if not w in stopwords] \n",
    "    return( \" \".join( meaningful_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_texts[\"tweet_to_words\"] = tweets_texts.apply(lambda row: tweet_to_words(row[\"text\"]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train,test = train_test_split(tweets_texts,test_size=0.3,random_state=42)\n",
    "train_clean_tweet=[]\n",
    "for tweet in train['tweet_to_words']:\n",
    "    train_clean_tweet.append(tweet)\n",
    "test_clean_tweet=[]\n",
    "for tweet in test['tweet_to_words']:\n",
    "    test_clean_tweet.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer = \"word\")),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "])\n",
    "#v = CountVectorizer(analyzer = \"word\")\n",
    "train_features= pipeline.fit_transform(train_clean_tweet)\n",
    "test_features=pipeline.transform(test_clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dense_features=train_features.toarray()\n",
    "dense_test= test_features.toarray()\n",
    "Accuracy=[]\n",
    "Model=[]\n",
    "for classifier in Classifiers:\n",
    "    try:\n",
    "        fit = classifier.fit(train_features,train['airline_sentiment'])\n",
    "        pred = fit.predict(test_features)\n",
    "    except Exception:\n",
    "        fit = classifier.fit(dense_features,train['airline_sentiment'])\n",
    "        pred = fit.predict(dense_test)\n",
    "    #accuracy = accuracy_score(pred,test['airline_sentiment'])\n",
    "    accuracy = f1_score(pred, test['airline_sentiment'], average=\"macro\")\n",
    "    Accuracy.append(accuracy)\n",
    "    Model.append(classifier.__class__.__name__)\n",
    "    print('Accuracy of '+classifier.__class__.__name__+'is '+str(accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest = Classifiers[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def report(results, n_top=5):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [10, 3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(2, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(train_features, train['airline_sentiment'])\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.cv_results_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [10, 3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(train_features, train['airline_sentiment'])\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.cv_results_['params'])))\n",
    "report(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_grid = {\"max_depth\": [10, 3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "\n",
    "# To apply an classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200)\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    #clf = GridSearchCV(rfc, param_grid, cv=5, scoring='%s_macro' % score)\n",
    "    clf = GridSearchCV(rfc, param_grid, cv=5)\n",
    "    clf.fit(train_features, train['airline_sentiment'])\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(clf.cv_results_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    #means = clf.cv_results_['mean_test_score']\n",
    "    #stds = clf.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "    #          % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = test['airline_sentiment'], clf.predict(test_features)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
